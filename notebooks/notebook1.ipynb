{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ECIR 2021 Tutorial Notebook - Part 1.ipynb","provenance":[{"file_id":"1kWCNf3QlQ4bX5YCM9OJBaaLikoTFCd5A","timestamp":1615914442515},{"file_id":"17Pihqt_C8DFzqlomTUks-5stNzNFjrAn","timestamp":1611078807322},{"file_id":"121AtOADdFd2VVAX5hcJX0WNBNt2_QHDu","timestamp":1609952873856},{"file_id":"1o4RTKOutf_FlMyPdEPkRyutnbY26JXMf","timestamp":1571324862553}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6UxEkLc6yz6J"},"source":["# PyTerrier ECIR Tutorial Notebook - Part 1\n","\n","This is one of a series of Colab notebooks created for the [ECIR 2021](https://www.ecir2021.eu) Tutorial entitled '**IR From Bag-of-words to BERT and Beyond through Practical Experiment**'. It demonstrates the use of [PyTerrier](https://github.com/terrier-org/pyterrier) on the [CORD19 test collection](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge).\n","\n","In particular, this notebooks has the following learning outcomes:\n","  - PyTerrier installation & configuration\n","  - indexing a collection\n","  - accessing an index\n","  - using the `BatchRetrieve` transformer for searching an index\n","  - conducting an `Experiment` \n","\n","Pre-requisites:\n"," - We assume that you are confident in programming Python, including [lambda functions](https://www.w3schools.com/python/python_lambda.asp).\n"," - We will **only be supporting notebooks on the Google Colab platform**.\n","  > *Explanation*: PyTerrier uses [pytrec_eval](https://github.com/cvangysel/pytrec_eval) for evaluation, which does not yet easily install on Windows. It will work fine on Linux and macOS, but only if you have the appropriate compilers installed. Hence, we prefer Google Colab.\n","\n","Related Reading:\n"," - [Pandas documentation](https://pandas.pydata.org/docs/)\n"," - [PyTerrier documentation](https://pyterrier.readthedocs.io/en/latest/)\n"]},{"cell_type":"markdown","metadata":{"id":"7u2hD-zBzfpR"},"source":["PyTerrier is a Python framework, but uses the underlying [Terrier information retrieval toolkit](http://terrier.org) for many indexing and retrieval operations. While PyTerrier was new in 2020, Terrier is written in Java and has a long history dating back to 2001. PyTerrier makes it easy to perform IR experiments in Python, but using the mature Terrier platform for the expensive indexing and retrieval operations. \n","\n","In the following, we introduce everything you need to know about PyTerrier, and also provide appropriate links to relevant parts of the [PyTerrier documentation](https://pyterrier.readthedocs.io/en/latest/).\n"]},{"cell_type":"markdown","metadata":{"id":"iH0Ds2370V0G"},"source":["### Installation & Configuration\n","\n","PyTerrier is installed as follows. This might take a few minutes, so you can read on."]},{"cell_type":"code","metadata":{"id":"5oE5neAX0bkW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615971631411,"user_tz":-60,"elapsed":27839,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"02aff377-cd89-4055-c86f-01cc0a82375a"},"source":["!pip install python-terrier"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting python-terrier\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/5d/dc47e86714bb4e13399e190aa2bdcc6aadc26563124cb865c0bea0c47902/python-terrier-0.4.0.tar.gz (70kB)\n","\r\u001b[K     |████▋                           | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 20kB 24.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 28.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 40kB 25.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 51kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 61kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.1.5)\n","Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Collecting pytrec_eval>=0.5\n","  Downloading https://files.pythonhosted.org/packages/2e/03/e6e84df6a7c1265579ab26bbe30ff7f8c22745aa77e0799bba471c0a3a19/pytrec_eval-0.5.tar.gz\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from python-terrier) (4.41.1)\n","Collecting pyjnius~=1.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/b1/e33db12a20efe28b20fbcf4efc9b95a934954587cd7aa5998987a22e8885/pyjnius-1.3.0-cp37-cp37m-manylinux2010_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 10.5MB/s \n","\u001b[?25hCollecting matchpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/25/6b8fa5846476c2d56856a4926fda859b218656b14571ace76fbcd1d39986/matchpy-0.5.4-py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n","\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.0)\n","Collecting deprecation\n","  Downloading https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl\n","Collecting chest\n","  Downloading https://files.pythonhosted.org/packages/18/66/b883b9a26cd2f777dd04b7eedc842d31ea1567b7709b049d46eca418501e/chest-0.2.3.tar.gz\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.23.0)\n","Collecting nptyping\n","  Downloading https://files.pythonhosted.org/packages/f1/1e/1af177efdf368b65831ea999e0a68f5320f8009f28dbc1a46db091ffdb24/nptyping-1.4.0-py3-none-any.whl\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.8.9)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.11.3)\n","Collecting sphinx_rtd_theme\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/81/d5af3a50a45ee4311ac2dac5b599d69f68388401c7a4ca902e0e450a9f94/sphinx_rtd_theme-0.5.1-py2.py3-none-any.whl (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 33.3MB/s \n","\u001b[?25hRequirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from python-terrier) (8.7.0)\n","Collecting myst_parser\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/bc/810dd8c332a4fc76ce4ea6246b0b61799ef97e4bcb1d532cd3df602806cd/myst_parser-0.13.5-py3-none-any.whl (44kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n","\u001b[?25hCollecting ir_datasets>=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/3a/6a5227baca7840943cdb2848b52d4c7696d958f9603e3d3e0578d3733bf9/ir_datasets-0.3.3-py3-none-any.whl (163kB)\n","\u001b[K     |████████████████████████████████| 163kB 45.0MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2.8.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (0.29.22)\n","Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (1.15.0)\n","Collecting multiset<3.0,>=2.0\n","  Downloading https://files.pythonhosted.org/packages/a8/12/813a649f5bc9801865dc6cda95b8f169f784d996322db192907ebe399064/multiset-2.1.1-py2.py3-none-any.whl\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->python-terrier) (0.22.2.post1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation->python-terrier) (20.9)\n","Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from chest->python-terrier) (1.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2020.12.5)\n","Collecting typish>=1.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/10/84e80246203f017fd27559b49557753d96cee860754247b7b023fd03d236/typish-1.9.1-py3-none-any.whl (44kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->python-terrier) (1.1.1)\n","Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from sphinx_rtd_theme->python-terrier) (1.8.5)\n","Collecting mdit-py-plugins~=0.2.5\n","  Downloading https://files.pythonhosted.org/packages/0c/31/f0ecaccf7cd2db17332a94852f190840167c3cb7eadf09efe498412f909a/mdit_py_plugins-0.2.6-py3-none-any.whl\n","Collecting markdown-it-py~=0.6.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/cb/8493188845d26599170268bb0e0a63e75584d5e7f130488c641e96449cd7/markdown_it_py-0.6.2-py3-none-any.whl (81kB)\n","\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from myst_parser->python-terrier) (3.13)\n","Requirement already satisfied: docutils>=0.15 in /usr/local/lib/python3.7/dist-packages (from myst_parser->python-terrier) (0.16)\n","Collecting warc3-wet>=0.2.3\n","  Downloading https://files.pythonhosted.org/packages/78/de/017a6bc2e3ba1ad912a08501f58414dd9e8503da1d6239aad548631777ad/warc3_wet-0.2.3-py3-none-any.whl\n","Collecting trec-car-tools>=2.5.4\n","  Downloading https://files.pythonhosted.org/packages/d1/e2/da4e895e5ad519f9f6aa464530dd482c7132c92a55cf178b8132e84b5c1d/trec_car_tools-2.5.4-py3-none-any.whl\n","Collecting zlib-state>=0.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/05/95df36be761a5ff85a39b438d87937f02762c19fea95c0f10b679a259f14/zlib_state-0.1.3-cp37-cp37m-manylinux2010_x86_64.whl (72kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n","\u001b[?25hCollecting warc3-wet-clueweb09>=0.2.5\n","  Downloading https://files.pythonhosted.org/packages/9f/c1/dd817bf57e0274dacb10e0ac868cb6cd70876950cf361c41879c030a2b8b/warc3-wet-clueweb09-0.2.5.tar.gz\n","Collecting ijson>=3.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0c/e3b7bf52e23345d5f9a6a3ff6de0cad419c96491893ab60cbbe9161644a8/ijson-3.1.4-cp37-cp37m-manylinux2010_x86_64.whl (126kB)\n","\u001b[K     |████████████████████████████████| 133kB 51.1MB/s \n","\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets>=0.2.0->python-terrier) (4.6.3)\n","Collecting lz4>=3.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/52/151c815a486290608e4dc6699a0cfd74141dc5191f8fe928e7d1b28b569e/lz4-3.1.3-cp37-cp37m-manylinux2010_x86_64.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 51.8MB/s \n","\u001b[?25hCollecting lxml>=4.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/88/b25778f17e5320c1c58f8c5060fb5b037288e162bd7554c30799e9ea90db/lxml-4.6.2-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n","\u001b[K     |████████████████████████████████| 5.5MB 37.7MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->python-terrier) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation->python-terrier) (2.4.7)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx_rtd_theme->python-terrier) (1.2.4)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx_rtd_theme->python-terrier) (2.1.0)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx_rtd_theme->python-terrier) (1.2.0)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx_rtd_theme->python-terrier) (2.9.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx_rtd_theme->python-terrier) (0.7.12)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx_rtd_theme->python-terrier) (2.6.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx_rtd_theme->python-terrier) (54.0.0)\n","Requirement already satisfied: attrs<21,>=19 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py~=0.6.2->myst_parser->python-terrier) (20.3.0)\n","Collecting cbor>=1.0.0\n","  Downloading https://files.pythonhosted.org/packages/9b/99/01c6a987c920500189eb74a291bd3a388e6c7cf85736bb6b066d9833315e/cbor-1.0.0.tar.gz\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->sphinx_rtd_theme->python-terrier) (1.1.4)\n","Building wheels for collected packages: python-terrier, wget, pytrec-eval, chest, warc3-wet-clueweb09, cbor\n","  Building wheel for python-terrier (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-terrier: filename=python_terrier-0.4.0-cp37-none-any.whl size=76208 sha256=31479725fca81464c8d42664dc103896f9cc02a4ef8d2d5e788a40d84eb3ad86\n","  Stored in directory: /root/.cache/pip/wheels/1a/08/00/1eb79fd13e6095132bf00bd92f803e90797813f40429485461\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=4064ec6811ad01bc825fe6c05f4296232c5867664561723936a4aa2c87368dff\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","  Building wheel for pytrec-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytrec-eval: filename=pytrec_eval-0.5-cp37-cp37m-linux_x86_64.whl size=264185 sha256=6649f6fb5468829e88b97ff782e7baec8f129758d3f5edb995505fd15a66603e\n","  Stored in directory: /root/.cache/pip/wheels/55/66/40/1779aa0a8eb66e088669befe286f695cdfe420ba91ce662127\n","  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for chest: filename=chest-0.2.3-cp37-none-any.whl size=7623 sha256=477bb75bbb51b8fa93984ab8a8e6f006c03ab2d7f8f683afb3489ea5bdc148f9\n","  Stored in directory: /root/.cache/pip/wheels/f9/52/97/3f0eb272609dc1b7a20fb678a45003301b51f03cf766f6237f\n","  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-cp37-none-any.whl size=18909 sha256=e3551594d079a8882b9c22e972949d1e9df15f8a8a082ed94b66fb052186af85\n","  Stored in directory: /root/.cache/pip/wheels/09/da/a9/ec9816edf7f789eab3fea2e57abe37bf7d6ab65f8ef8ee7f31\n","  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cbor: filename=cbor-1.0.0-cp37-cp37m-linux_x86_64.whl size=51267 sha256=0c99ea309f16c741ebc666c1a6a1969e4e0625c7deed56bdc614333e51f37b39\n","  Stored in directory: /root/.cache/pip/wheels/40/5c/a5/e6d629446a6a687ba328c55f1589234c29b99ef35b1a65dbaa\n","Successfully built python-terrier wget pytrec-eval chest warc3-wet-clueweb09 cbor\n","\u001b[31mERROR: myst-parser 0.13.5 has requirement sphinx<4,>=2, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: ir-datasets 0.3.3 has requirement pyyaml>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n","Installing collected packages: wget, pytrec-eval, pyjnius, multiset, matchpy, deprecation, chest, typish, nptyping, sphinx-rtd-theme, markdown-it-py, mdit-py-plugins, myst-parser, warc3-wet, cbor, trec-car-tools, zlib-state, warc3-wet-clueweb09, ijson, lz4, lxml, ir-datasets, python-terrier\n","  Found existing installation: lxml 4.2.6\n","    Uninstalling lxml-4.2.6:\n","      Successfully uninstalled lxml-4.2.6\n","Successfully installed cbor-1.0.0 chest-0.2.3 deprecation-2.1.0 ijson-3.1.4 ir-datasets-0.3.3 lxml-4.6.2 lz4-3.1.3 markdown-it-py-0.6.2 matchpy-0.5.4 mdit-py-plugins-0.2.6 multiset-2.1.1 myst-parser-0.13.5 nptyping-1.4.0 pyjnius-1.3.0 python-terrier-0.4.0 pytrec-eval-0.5 sphinx-rtd-theme-0.5.1 trec-car-tools-2.5.4 typish-1.9.1 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JUN1B8RI0gPC"},"source":["The next step is to initialise PyTerrier. This is performed using PyTerrier's `init()` method. The `init()` method is needed as PyTerrier must download Terrier's jar file and start the Java virtual machine. We prevent `init()` from being called more than once by checking `started()`."]},{"cell_type":"code","metadata":{"id":"Z4qALBa90-7g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615971633689,"user_tz":-60,"elapsed":17656,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"378c8773-686c-4abc-d1b5-af80d18cfed0"},"source":["import pyterrier as pt\n","if not pt.started():\n","  pt.init()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n","  from pandas import Panel\n"],"name":"stderr"},{"output_type":"stream","text":["terrier-assemblies 5.4  jar-with-dependencies not found, downloading to /root/.pyterrier...\n","Done\n","terrier-python-helper 0.0.5  jar not found, downloading to /root/.pyterrier...\n","Done\n","PyTerrier 0.4.0 has loaded Terrier 5.4 (built by craigm on 2021-01-16 14:17)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-qqjVSu-5_FX"},"source":["### Documents, Indexing and Indexes"]},{"cell_type":"markdown","metadata":{"id":"3soS1IIy5B83"},"source":["Much of PyTerrier's view of the world is wrapped up in Pandas dataframes. Let's consider some textual documents in a dataframe.\n"]},{"cell_type":"code","metadata":{"id":"gSEiEuTE5uyL","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1615971633692,"user_tz":-60,"elapsed":14933,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"8ef282f5-94df-403f-c501-6147f62d2de8"},"source":["# we need to import pandas. We commonly rename it to pd, to make commands shorter\n","import pandas as pd\n","\n","# lets not truncate output too much\n","pd.set_option('display.max_colwidth', 150)\n","\n","docs_df = pd.DataFrame([\n","        [\"d1\", \"this is the first document of many documents\"],\n","        [\"d2\", \"this is another document\"],\n","        [\"d3\", \"the topic of this document is unknown\"]\n","    ], columns=[\"docno\", \"text\"])\n","\n","docs_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>docno</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>d1</td>\n","      <td>this is the first document of many documents</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d2</td>\n","      <td>this is another document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>d3</td>\n","      <td>the topic of this document is unknown</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  docno                                          text\n","0    d1  this is the first document of many documents\n","1    d2                      this is another document\n","2    d3         the topic of this document is unknown"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"2RCtCCTU6GAj"},"source":["Before any search engine can estimate which documents are most likely to be relevant for a given query, it must index the documents. \n","\n","In the following cell, we index the dataframe's documents. The index, with all its data structures, is written into a directory called `index_3docs`. "]},{"cell_type":"code","metadata":{"id":"1YvLhEOS6V8w","colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"status":"ok","timestamp":1615971681350,"user_tz":-60,"elapsed":2312,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"ebe4070d-7160-42ba-bbfe-e5ccc2f3165b"},"source":["indexer = pt.DFIndexer(\"./index_3docs\", overwrite=True)\n","index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n","index_ref.toString()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./index_3docs/data.properties'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"TUm6r6_625gW"},"source":["An `IndexRef`\n"," is essentially a string saying where an index is stored. Indeed, we can look in the `index_3docs` directory and see that it has created various small files: "]},{"cell_type":"code","metadata":{"id":"TF45pl5O8p7R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615971697027,"user_tz":-60,"elapsed":581,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"c039d811-aebe-4e4d-f1d4-18b2b989d4c5"},"source":["!ls -lh index_3docs/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 36K\n","-rw-r--r-- 1 root root    3 Mar 17 09:01 data.direct.bf\n","-rw-r--r-- 1 root root   51 Mar 17 09:01 data.document.fsarrayfile\n","-rw-r--r-- 1 root root    4 Mar 17 09:01 data.inverted.bf\n","-rw-r--r-- 1 root root  344 Mar 17 09:01 data.lexicon.fsomapfile\n","-rw-r--r-- 1 root root  249 Mar 17 09:01 data.lexicon.fsomaphash\n","-rw-r--r-- 1 root root   24 Mar 17 09:01 data.meta.idx\n","-rw-r--r-- 1 root root   36 Mar 17 09:01 data.meta.zdata\n","-rw-r--r-- 1 root root 4.1K Mar 17 09:01 data.properties\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B2b8isFP3Kv6"},"source":["With an `IndexRe`, we can load it to an actual index. The method `pt.IndexFactory.of()` is the relevant factory. "]},{"cell_type":"code","metadata":{"id":"TTM17szD6pNy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615971763026,"user_tz":-60,"elapsed":587,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"0d00514e-b30f-4b0c-a991-d618d24bb756"},"source":["index = pt.IndexFactory.of(index_ref)\n","\n","#lets see what type index is.\n","type(index)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["jnius.reflect.org.terrier.structures.Index"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"mZe3HD5i7G3v"},"source":["Ok, so this object refers to Terrier's [`Index`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Index.html) type. Check the linked Javadoc – you will see that this Java object has methods such as:\n"," - `getCollectionStatistics()`\n"," - `getInvertedIndex()`\n"," - `getLexicon()`\n","\n","Let's see what is returned by the `CollectionStatistics()` method:"]},{"cell_type":"code","metadata":{"id":"6-gXEDSX65bx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615972787602,"user_tz":-60,"elapsed":629,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"5491223b-5b50-48c2-8232-d75970e2c2ae"},"source":["print(index.getCollectionStatistics().toString())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of documents: 3\n","Number of terms: 4\n","Number of postings: 6\n","Number of fields: 0\n","Number of tokens: 7\n","Field names: []\n","Positions:   false\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i6HrR4lc7i10"},"source":["Ok, that seems fair – we have 3 documents. But why only 4 terms? \n","Let's check the [`Lexicon`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Lexicon.html), which is our vocabulary. Fortunately, the `Lexicon` can be iterated easily from Python:"]},{"cell_type":"code","metadata":{"id":"us2mAzTW7Bny","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615971875714,"user_tz":-60,"elapsed":585,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"e10d37e2-84a4-448d-9ed9-3d72a5ad5ab7"},"source":["for kv in index.getLexicon():\n","  print(\"%s (%s) -> %s (%s)\" % (kv.getKey(), type(kv.getKey()), kv.getValue().toString(), type(kv.getValue()) ) )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["document (<class 'str'>) -> term0 Nt=3 TF=4 maxTF=2 @{0 0 0} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","first (<class 'str'>) -> term1 Nt=1 TF=1 maxTF=1 @{0 0 7} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","topic (<class 'str'>) -> term2 Nt=1 TF=1 maxTF=1 @{0 1 1} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","unknown (<class 'str'>) -> term3 Nt=1 TF=1 maxTF=1 @{0 1 5} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fwbp94gh86pw"},"source":["Here, iterating over the `Lexicon` returns a pair of `String ` term and a [`LexiconEntry`](http://terrier.org/docs/current/javadoc/org/terrier/structures/LexiconEntry.html) object – which itself is an [`EntryStatistics`](http://terrier.org/docs/current/javadoc/org/terrier/structures/EntryStatistics.html) – and contains information including the statistics of that term.\n","\n","\n","So what did we find? Here are some observations:\n"," - we only have 4 unique terms, as stopwords were removed;\n"," - we have one term for `\"document\"`, even though `\"documents\"` occurred in document \"`d1`\". \n"," \n","Both these observations make sense, as indeed Terrier removes standard stopwords and applies Porter's stemmer by default.\n","\n","Further:\n"," - `Nt` is the number of unique documents that each term occurs in – this is useful for calculating IDF.\n"," - `TF` is the total number of occurrences – some weighting models use this instead of Nt.\n"," - The numbers in the `@{}` are a pointer – they tell Terrier where the postings are for that term in the inverted index data structure.\n","\n","Finally, we can also use the square bracket notation to lookup terms in Terrier's lexicon:\n"]},{"cell_type":"code","metadata":{"id":"SZmi9498-Ijw","colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"status":"ok","timestamp":1615972070133,"user_tz":-60,"elapsed":591,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"1dccc860-2f99-4e62-b1cc-da4918003b11"},"source":["index.getLexicon()[\"document\"].toString()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'term0 Nt=3 TF=4 maxTF=2 @{0 0 0}'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"vaKaU59l-kzg"},"source":["Let's now think about the inverted index. Remember that the inverted index tells us in which *documents* each term occurs in. The `LexiconEntry` is the pointer that tell us where to find the postings for that term in the inverted index."]},{"cell_type":"code","metadata":{"id":"XQki_Pds8ut2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615972108524,"user_tz":-60,"elapsed":640,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"f7824c65-33d9-499f-f9dc-97d8d7e652c5"},"source":["pointer = index.getLexicon()[\"document\"]\n","for posting in index.getInvertedIndex().getPostings(pointer):\n","    print(posting.toString() + \" doclen=%d\" % posting.getDocumentLength())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ID(0) TF(2) doclen=3\n","ID(1) TF(1) doclen=1\n","ID(2) TF(1) doclen=3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l7EaoIIO_DPx"},"source":["Ok, so we can see that `\"document\"` occurs once in each of the three documents. \n","\n","NB: Terrier counts documents as integers from 0 (called *docids*). It records the mapping back to *docnos* (the string form, i.e. \"`d1`\", \"`d2`\") in a separate data structure called the *metaindex*."]},{"cell_type":"markdown","metadata":{"id":"zOSdVAr-CGRf"},"source":["### Searching an Index\n","\n","Our way into search in PyTerrier is called `BatchRetrieve`. BatchRetrieve is configured by specifying an index and a weighting model (`Tf` in our example). We then search for a single-word query, `\"document\"`."]},{"cell_type":"code","metadata":{"id":"XtK93nwXCF5C","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1615972796605,"user_tz":-60,"elapsed":1097,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"f10dccb8-7d91-44ba-8afa-b21b32022999"},"source":["br = pt.BatchRetrieve(index, wmodel=\"Tf\")\n","br.search(\"document\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score     query\n","0   1      0    d1     0    2.0  document\n","1   1      2    d3     1    1.0  document\n","2   1      1    d2     2    1.0  document"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"BHqSfTCtDM2T"},"source":["So the `search()` method returns a dataframe with columns:\n"," - `qid`: this is by default \"1\", since it's our first and only query\n"," - `docid`: Terrier' internal integer for each document\n"," - `docno`: the external (string) unique identifier for each document\n"," - `score`: since we use the `Tf` weighting model, this score corresponds the total frequency of the query (terms) in each document\n"," - `rank`: A handy attribute showing the descending order by score\n"," - `query`: the input query\n","\n","As expected, the `Tf` weighting model used here only counts the frequencies of the query terms in each document, i.e.:\n","$$\n","score(d,q) = \\sum_{t \\in q} tf_{t,d}\n","$$\n","\n","Hence, it's clear that document `d1` should be the highest scored document with two occurrences (c.f. `'document'` and `'documents'`).  "]},{"cell_type":"markdown","metadata":{"id":"BJBXquPOD6q7"},"source":["We can also pass a dataframe of one or more queries to the `transform()` method (rather than the `search()` method) of a transformer, with queries numbered \"q1\", \"q2\" etc.. "]},{"cell_type":"code","metadata":{"id":"TPBmPOETBKWk","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"ok","timestamp":1615972799893,"user_tz":-60,"elapsed":566,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"69bf68d3-5e95-403d-f5f8-76bbd7cdaba9"},"source":["import pandas as pd\n","queries = pd.DataFrame([[\"q1\", \"document\"], [\"q2\", \"first document\"]], columns=[\"qid\", \"query\"])\n","br.transform(queries)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q2</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q2</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>q2</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score           query\n","0  q1      0    d1     0    2.0        document\n","1  q1      2    d3     1    1.0        document\n","2  q1      1    d2     2    1.0        document\n","3  q2      0    d1     0    3.0  first document\n","4  q2      2    d3     1    1.0  first document\n","5  q2      1    d2     2    1.0  first document"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"tcgDzFLBEWAI"},"source":["In fact, we are usually calling `transform()`, so it's the default method – i.e. \n","`br.transform(queries)` can be more succinctly written as `br(queries)`."]},{"cell_type":"code","metadata":{"id":"YCwxb3HhEOp_","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"ok","timestamp":1615972806683,"user_tz":-60,"elapsed":655,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"b0cfe94b-c1d7-4ac8-811d-befc9771ce32"},"source":["br(queries)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q2</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q2</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>q2</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score           query\n","0  q1      0    d1     0    2.0        document\n","1  q1      2    d3     1    1.0        document\n","2  q1      1    d2     2    1.0        document\n","3  q2      0    d1     0    3.0  first document\n","4  q2      2    d3     1    1.0  first document\n","5  q2      1    d2     2    1.0  first document"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"ldY8VV8wQ60Z"},"source":["### CORD19\n","\n","OK, having 3 documents is quite trivial, so let's move upto a slightly larger corpus of documents. We'll be using the CORD19 datasets for the remainder of this tutorial. PyTerrier has a handy `get_dataset()` API, which allows us to download the corpus and index it."]},{"cell_type":"code","metadata":{"id":"L2lJsK-vEcQx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615972928650,"user_tz":-60,"elapsed":120273,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"bcdfe9c5-7950-4974-a97d-ab3764995115"},"source":["import os\n","\n","cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n","pt_index_path = './terrier_cord19'\n","\n","if not os.path.exists(pt_index_path + \"/data.properties\"):\n","  # create the index, using the IterDictIndexer indexer \n","  indexer = pt.index.IterDictIndexer(pt_index_path)\n","\n","  # we give the dataset get_corpus_iter() directly to the indexer\n","  # while specifying the fields to index and the metadata to record\n","  index_ref = indexer.index(cord19.get_corpus_iter(), \n","                            fields=('abstract',), \n","                            meta=('docno',))\n","\n","else:\n","  # if you already have the index, use it.\n","  index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n","index = pt.IndexFactory.of(index_ref)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] If you have a local copy of https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv, you can symlink it here to avoid downloading it again: /root/.ir_datasets/downloads/80d664e496b8b7e50a39c6f6bb92e0ef\n","[INFO] [starting] https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv\n","[INFO] [finished] https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-07-16/metadata.csv: [00:15] [269MB] [17.6MB/s]\n","[INFO] [starting] building docstore\n","docs_iter: 192509it [00:12, 15799.08it/s]\n","[INFO] [finished] docs_iter: [00:12] [192509it] [15798.06it/s]\n","[INFO] [finished] building docstore [12.19s]\n","cord19/trec-covid documents:   0%|          | 49/192509 [00:00<16:09, 198.47it/s]"],"name":"stderr"},{"output_type":"stream","text":["09:20:38.367 [ForkJoinPool-1-worker-3] WARN  o.t.structures.indexing.Indexer - Adding an empty document to the index (6iu1dtyl) - further warnings are suppressed\n"],"name":"stdout"},{"output_type":"stream","text":["cord19/trec-covid documents: 100%|██████████| 192509/192509 [01:22<00:00, 2324.61it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["09:22:00.918 [ForkJoinPool-1-worker-3] WARN  o.t.structures.indexing.Indexer - Indexed 54937 empty documents\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y7GK9uANRt8w"},"source":["#### Task 1\n","- What are the statistics of our index?\n","- Can you get a feeling for what kind of documents this index contains by inspecting a few documents. e.g. look into the content of the index of docids 0, 10 and 100"]},{"cell_type":"code","metadata":{"id":"bNAVqf9uRr2p"},"source":["#YOUR SOLUTION"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FyIZZjiH2ZaL","executionInfo":{"status":"ok","timestamp":1615972937388,"user_tz":-60,"elapsed":608,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"bd16615f-ae01-4809-da1e-fa6dbee9fa39"},"source":["#@title\n","print(index.getCollectionStatistics().toString())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of documents: 192509\n","Number of terms: 151235\n","Number of postings: 11554033\n","Number of fields: 1\n","Number of tokens: 17728468\n","Field names: [abstract]\n","Positions:   false\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tQD9Q8CqSirN"},"source":["Next, CORD19 also has a corresponding set of queries and relevance assessments (aka qrels), thus forming a *test collection*, \n","\n","We can easily access the topics and qrels from the dataset. Indeed these are expressed as dataframes as well (we use Pandas's [`head()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method to show only the first 5 topics):"]},{"cell_type":"code","metadata":{"id":"8n7oY-YYS_-A","colab":{"base_uri":"https://localhost:8080/","height":275},"executionInfo":{"status":"ok","timestamp":1615972942774,"user_tz":-60,"elapsed":961,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"6ff6f437-725f-4b92-bfab-787e18386941"},"source":["cord19.get_topics(variant='title').head(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] If you have a local copy of https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml, you can symlink it here to avoid downloading it again: /root/.ir_datasets/downloads/0307a37b6b9f1a5f233340a769d538ea\n","[INFO] [starting] https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml\n","[INFO] [finished] https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml: [00:00] [18.7kB] [7.11MB/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>coronavirus origin</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>coronavirus response to weather changes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>coronavirus immunity</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>how do people die from the coronavirus</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>animal models of COVID-19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid                                    query\n","0   1                       coronavirus origin\n","1   2  coronavirus response to weather changes\n","2   3                     coronavirus immunity\n","3   4   how do people die from the coronavirus\n","4   5                animal models of COVID-19"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"-rYxqvhJTGNX","colab":{"base_uri":"https://localhost:8080/","height":275},"executionInfo":{"status":"ok","timestamp":1615972945620,"user_tz":-60,"elapsed":1704,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"e4db9772-f10f-4133-bc25-aee1a6f5a0ba"},"source":["cord19.get_qrels().head(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] If you have a local copy of https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt, you can symlink it here to avoid downloading it again: /root/.ir_datasets/downloads/8138424a59daea0aba751c8a891e5f54\n","[INFO] [starting] https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt\n","[INFO] [finished] https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt: [00:00] [1.14MB] [2.61MB/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docno</th>\n","      <th>label</th>\n","      <th>iteration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>005b2j4b</td>\n","      <td>2</td>\n","      <td>4.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>00fmeepz</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>010vptx3</td>\n","      <td>2</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0194oljo</td>\n","      <td>1</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>021q9884</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid     docno  label iteration\n","0   1  005b2j4b      2       4.5\n","1   1  00fmeepz      1         4\n","2   1  010vptx3      2       0.5\n","3   1  0194oljo      1       2.5\n","4   1  021q9884      1         4"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"2Gop4-jVbIIu"},"source":["### Weighting Models\n","\n","So far, we have been using the simple \"`Tf`\" as our ranking function for document retrieval in BatchRetrieve. However, we can use other models such as `\"TF_IDF\"` by simply changing the `wmodel=\"Tf\"` keyword argument in the constructor of `BatchRetrieve`.\n"]},{"cell_type":"code","metadata":{"id":"Cg8AGzCibdPG","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1615973062514,"user_tz":-60,"elapsed":945,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"bc353f41-1c33-468c-a834-37a93f1d0ced"},"source":["tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n","tfidf.search(\"chemical reactions\")\n","#tfidf.transform(dataset.get_topics(variant='title').head(2))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>18717</td>\n","      <td>iavwkdpr</td>\n","      <td>0</td>\n","      <td>11.035982</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>171636</td>\n","      <td>v3blnh02</td>\n","      <td>1</td>\n","      <td>10.329726</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>147193</td>\n","      <td>ei4rb8fr</td>\n","      <td>2</td>\n","      <td>10.317138</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>121217</td>\n","      <td>msdycum2</td>\n","      <td>3</td>\n","      <td>9.653734</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>170863</td>\n","      <td>sj8i9ss2</td>\n","      <td>4</td>\n","      <td>9.500211</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>1</td>\n","      <td>149517</td>\n","      <td>6i3x49p8</td>\n","      <td>995</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>1</td>\n","      <td>2428</td>\n","      <td>38aabxh1</td>\n","      <td>996</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>1</td>\n","      <td>20074</td>\n","      <td>wxi1xsbo</td>\n","      <td>997</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>1</td>\n","      <td>117156</td>\n","      <td>ts3obwts</td>\n","      <td>998</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1</td>\n","      <td>14752</td>\n","      <td>u709r8ss</td>\n","      <td>999</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 6 columns</p>\n","</div>"],"text/plain":["    qid   docid     docno  rank      score               query\n","0     1   18717  iavwkdpr     0  11.035982  chemical reactions\n","1     1  171636  v3blnh02     1  10.329726  chemical reactions\n","2     1  147193  ei4rb8fr     2  10.317138  chemical reactions\n","3     1  121217  msdycum2     3   9.653734  chemical reactions\n","4     1  170863  sj8i9ss2     4   9.500211  chemical reactions\n","..   ..     ...       ...   ...        ...                 ...\n","995   1  149517  6i3x49p8   995   3.790183  chemical reactions\n","996   1    2428  38aabxh1   996   3.790183  chemical reactions\n","997   1   20074  wxi1xsbo   997   3.790183  chemical reactions\n","998   1  117156  ts3obwts   998   3.790183  chemical reactions\n","999   1   14752  u709r8ss   999   3.790183  chemical reactions\n","\n","[1000 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"m6aZGX9sbdmc"},"source":["You will note that, as expected, the scores of documents ranked by `TF_IDF` are no longer integers. You can see the exact formula used by Terrier from [the Github repo](https://github.com/terrier-org/terrier-core/blob/5.x/modules/core/src/main/java/org/terrier/matching/models/TF_IDF.java#L79).\n","\n","Terrier supports many weighting models – the documentation contains [a list of supported models](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html) - some of which we will discover later in the tutorial.\n"]},{"cell_type":"markdown","metadata":{"id":"YQ0j9lFfx-gO"},"source":["### What is Success?\n","\n","So far, we have been creating search engine models, but we haven't decided if any of them ia actually any good. Let's investigate if we are getting a correct (\"relevant\") document at the first rank."]},{"cell_type":"code","metadata":{"id":"iyShZYpwwNSx","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1615973109097,"user_tz":-60,"elapsed":794,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"91f1ae8b-8f3a-4547-ae37-d9d808c970ce"},"source":["qrels = cord19.get_qrels()\n","def get_res_with_labels(ranker, df):\n","  # get the results for the query or queries\n","  results = ranker( df )\n","  # left outer join with the qrels\n","  with_labels = results.merge(qrels, on=[\"qid\", \"docno\"], how=\"left\").fillna(0)\n","  return with_labels\n","\n","# lets get the Tf results for the first query\n","get_res_with_labels(tfidf, cord19.get_topics(variant='title').head(1))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","      <th>label</th>\n","      <th>iteration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>175892</td>\n","      <td>zy8qjaai</td>\n","      <td>0</td>\n","      <td>7.080599</td>\n","      <td>coronavirus origin</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>82224</td>\n","      <td>8ccl9aui</td>\n","      <td>1</td>\n","      <td>6.775667</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>135326</td>\n","      <td>ne5r4d4b</td>\n","      <td>2</td>\n","      <td>6.683114</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>187888</td>\n","      <td>hl967ekh</td>\n","      <td>3</td>\n","      <td>6.590340</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>122806</td>\n","      <td>4fb291hq</td>\n","      <td>4</td>\n","      <td>6.590340</td>\n","      <td>coronavirus origin</td>\n","      <td>1.0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>1</td>\n","      <td>88316</td>\n","      <td>yja3wzgg</td>\n","      <td>995</td>\n","      <td>4.214228</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>1</td>\n","      <td>148967</td>\n","      <td>f8vbflx6</td>\n","      <td>996</td>\n","      <td>4.212887</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>1</td>\n","      <td>183189</td>\n","      <td>uadfehr6</td>\n","      <td>997</td>\n","      <td>4.210201</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>1</td>\n","      <td>98707</td>\n","      <td>yscapx15</td>\n","      <td>998</td>\n","      <td>4.202319</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1</td>\n","      <td>131739</td>\n","      <td>64jykbec</td>\n","      <td>999</td>\n","      <td>4.202319</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 8 columns</p>\n","</div>"],"text/plain":["    qid   docid     docno  rank     score               query  label iteration\n","0     1  175892  zy8qjaai     0  7.080599  coronavirus origin    1.0         1\n","1     1   82224  8ccl9aui     1  6.775667  coronavirus origin    2.0         1\n","2     1  135326  ne5r4d4b     2  6.683114  coronavirus origin    0.0       1.5\n","3     1  187888  hl967ekh     3  6.590340  coronavirus origin    2.0         3\n","4     1  122806  4fb291hq     4  6.590340  coronavirus origin    1.0         3\n","..   ..     ...       ...   ...       ...                 ...    ...       ...\n","995   1   88316  yja3wzgg   995  4.214228  coronavirus origin    0.0         0\n","996   1  148967  f8vbflx6   996  4.212887  coronavirus origin    0.0         0\n","997   1  183189  uadfehr6   997  4.210201  coronavirus origin    2.0       1.5\n","998   1   98707  yscapx15   998  4.202319  coronavirus origin    0.0         0\n","999   1  131739  64jykbec   999  4.202319  coronavirus origin    0.0         0\n","\n","[1000 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"OFUmiFSobUDg","executionInfo":{"status":"ok","timestamp":1615973119937,"user_tz":-60,"elapsed":3826,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"db01e114-e6e7-4ff4-9447-ecf5e3d8ea54"},"source":["pt.Experiment(\n","    [tfidf],\n","    cord19.get_topics(variant='title'),\n","    cord19.get_qrels(),\n","    eval_metrics=[\"map\", \"ndcg\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>map</th>\n","      <th>ndcg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BR(TF_IDF)</td>\n","      <td>0.135584</td>\n","      <td>0.304603</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         name       map      ndcg\n","0  BR(TF_IDF)  0.135584  0.304603"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"Mt0iPhRw2J-S"},"source":["## That's all folks\n","\n","The following parts of the PyTerrier documentation may be useful references for this notebook:\n"," * [PyTerrier datasets](https://pyterrier.readthedocs.io/en/latest/datasets.html)\n"," * [Using Terrier for retrieval](https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html)\n"," * [Transformers in PyTerrier](https://pyterrier.readthedocs.io/en/latest/transformer.html)\n"," * [Transformer Operators](https://pyterrier.readthedocs.io/en/latest/operators.html)"]},{"cell_type":"code","metadata":{"id":"mRjyEZ5_aTvM"},"source":[""],"execution_count":null,"outputs":[]}]}