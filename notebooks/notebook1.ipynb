{"cells":[{"cell_type":"markdown","metadata":{"id":"6UxEkLc6yz6J"},"source":["# PyTerrier ECIR Tutorial Notebook - Part 1\n","\n","This is one of a series of Colab notebooks created for the [ECIR 2021](https://www.ecir2021.eu) Tutorial entitled '**IR From Bag-of-words to BERT and Beyond through Practical Experiment**'. It demonstrates the use of [PyTerrier](https://github.com/terrier-org/pyterrier) on the [CORD19 test collection](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge).\n","\n","In particular, this notebooks has the following learning outcomes:\n","  - PyTerrier installation & configuration\n","  - indexing a collection\n","  - accessing an index\n","  - using the `BatchRetrieve` transformer for searching an index\n","  - conducting an `Experiment` \n","\n","Pre-requisites:\n"," - We assume that you are confident in programming Python, including [lambda functions](https://www.w3schools.com/python/python_lambda.asp).\n"," - We will **only be supporting notebooks on the Google Colab platform**.\n","  > *Explanation*: PyTerrier uses [pytrec_eval](https://github.com/cvangysel/pytrec_eval) for evaluation, which does not yet easily install on Windows. It will work fine on Linux and macOS, but only if you have the appropriate compilers installed. Hence, we prefer Google Colab.\n","\n","Related Reading:\n"," - [Pandas documentation](https://pandas.pydata.org/docs/)\n"," - [PyTerrier documentation](https://pyterrier.readthedocs.io/en/latest/)\n"]},{"cell_type":"markdown","metadata":{"id":"7u2hD-zBzfpR"},"source":["PyTerrier is a Python framework, but uses the underlying [Terrier information retrieval toolkit](http://terrier.org) for many indexing and retrieval operations. While PyTerrier was new in 2020, Terrier is written in Java and has a long history dating back to 2001. PyTerrier makes it easy to perform IR experiments in Python, but using the mature Terrier platform for the expensive indexing and retrieval operations. \n","\n","In the following, we introduce everything you need to know about PyTerrier, and also provide appropriate links to relevant parts of the [PyTerrier documentation](https://pyterrier.readthedocs.io/en/latest/).\n"]},{"cell_type":"markdown","metadata":{"id":"iH0Ds2370V0G"},"source":["### Installation & Configuration\n","\n","PyTerrier is installed as follows. This might take a few minutes, so you can read on."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27839,"status":"ok","timestamp":1615971631411,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"5oE5neAX0bkW","outputId":"02aff377-cd89-4055-c86f-01cc0a82375a"},"outputs":[],"source":["%pip install python-terrier"]},{"cell_type":"markdown","metadata":{"id":"JUN1B8RI0gPC"},"source":["The next step is to initialise PyTerrier. This is performed using PyTerrier's `init()` method. The `init()` method is needed as PyTerrier must download Terrier's jar file and start the Java virtual machine. We prevent `init()` from being called more than once by checking `started()`."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# déclaration de la variable JAVA_HOME\n","import os\n","os.environ['JAVA_HOME'] = '/opt/homebrew/opt/openjdk/libexec/openjdk.jdk/'\n","!export JAVA_HOME='/opt/homebrew/opt/openjdk/libexec/openjdk.jdk/'"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17656,"status":"ok","timestamp":1615971633689,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"Z4qALBa90-7g","outputId":"378c8773-686c-4abc-d1b5-af80d18cfed0"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n","\n","No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"]}],"source":["import pyterrier as pt\n","if not pt.started():\n","  pt.init()"]},{"cell_type":"markdown","metadata":{"id":"-qqjVSu-5_FX"},"source":["### Documents, Indexing and Indexes"]},{"cell_type":"markdown","metadata":{"id":"3soS1IIy5B83"},"source":["Much of PyTerrier's view of the world is wrapped up in Pandas dataframes. Let's consider some textual documents in a dataframe.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"elapsed":14933,"status":"ok","timestamp":1615971633692,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"gSEiEuTE5uyL","outputId":"8ef282f5-94df-403f-c501-6147f62d2de8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>docno</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>d1</td>\n","      <td>this is the first document of many documents</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d2</td>\n","      <td>this is another document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>d3</td>\n","      <td>the topic of this document is unknown</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  docno                                          text\n","0    d1  this is the first document of many documents\n","1    d2                      this is another document\n","2    d3         the topic of this document is unknown"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# we need to import pandas. We commonly rename it to pd, to make commands shorter\n","import pandas as pd\n","\n","# lets not truncate output too much\n","pd.set_option('display.max_colwidth', 150)\n","\n","docs_df = pd.DataFrame([\n","        [\"d1\", \"this is the first document of many documents\"],\n","        [\"d2\", \"this is another document\"],\n","        [\"d3\", \"the topic of this document is unknown\"]\n","    ], columns=[\"docno\", \"text\"])\n","\n","docs_df"]},{"cell_type":"markdown","metadata":{"id":"2RCtCCTU6GAj"},"source":["Before any search engine can estimate which documents are most likely to be relevant for a given query, it must index the documents. \n","\n","In the following cell, we index the dataframe's documents. The index, with all its data structures, is written into a directory called `index_3docs`. "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"elapsed":2312,"status":"ok","timestamp":1615971681350,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"1YvLhEOS6V8w","outputId":"ebe4070d-7160-42ba-bbfe-e5ccc2f3165b"},"outputs":[{"data":{"text/plain":["'./index_3docs/data.properties'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["indexer = pt.DFIndexer(\"./index_3docs\", overwrite=True)\n","index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n","index_ref.toString()"]},{"cell_type":"markdown","metadata":{"id":"TUm6r6_625gW"},"source":["An `IndexRef`\n"," is essentially a string saying where an index is stored. Indeed, we can look in the `index_3docs` directory and see that it has created various small files: "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":581,"status":"ok","timestamp":1615971697027,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"TF45pl5O8p7R","outputId":"c039d811-aebe-4e4d-f1d4-18b2b989d4c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 80\n","-rw-r--r--  1 asriel  staff     3B Mar  9 20:10 data.direct.bf\n","-rw-r--r--  1 asriel  staff    51B Mar  9 20:10 data.document.fsarrayfile\n","-rw-r--r--  1 asriel  staff     4B Mar  9 20:10 data.inverted.bf\n","-rw-r--r--  1 asriel  staff   344B Mar  9 20:10 data.lexicon.fsomapfile\n","-rw-r--r--  1 asriel  staff   249B Mar  9 20:10 data.lexicon.fsomaphash\n","-rw-r--r--  1 asriel  staff    33B Mar  9 20:10 data.meta-0.fsomapfile\n","-rw-r--r--  1 asriel  staff    24B Mar  9 20:10 data.meta.idx\n","-rw-r--r--  1 asriel  staff    48B Mar  9 20:10 data.meta.zdata\n","-rw-r--r--  1 asriel  staff   4.1K Mar  9 20:10 data.properties\n"]}],"source":["!ls -lh index_3docs/"]},{"cell_type":"markdown","metadata":{"id":"B2b8isFP3Kv6"},"source":["With an `IndexRef`, we can load it to an actual index. The method `pt.IndexFactory.of()` is the relevant factory. "]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587,"status":"ok","timestamp":1615971763026,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"TTM17szD6pNy","outputId":"0d00514e-b30f-4b0c-a991-d618d24bb756"},"outputs":[{"data":{"text/plain":["jnius.reflect.org.terrier.structures.Index"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["index = pt.IndexFactory.of(index_ref)\n","\n","#lets see what type index is.\n","type(index)"]},{"cell_type":"markdown","metadata":{"id":"mZe3HD5i7G3v"},"source":["Ok, so this object refers to Terrier's [`Index`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Index.html) type. Check the linked Javadoc – you will see that this Java object has methods such as:\n"," - `getCollectionStatistics()`\n"," - `getInvertedIndex()`\n"," - `getLexicon()`\n","\n","Let's see what is returned by the `CollectionStatistics()` method:"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":629,"status":"ok","timestamp":1615972787602,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"6-gXEDSX65bx","outputId":"5491223b-5b50-48c2-8232-d75970e2c2ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of documents: 3\n","Number of terms: 4\n","Number of postings: 6\n","Number of fields: 0\n","Number of tokens: 7\n","Field names: []\n","Positions:   false\n","\n"]}],"source":["print(index.getCollectionStatistics().toString())"]},{"cell_type":"markdown","metadata":{"id":"i6HrR4lc7i10"},"source":["Ok, that seems fair – we have 3 documents. But why only 4 terms? \n","Let's check the [`Lexicon`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Lexicon.html), which is our vocabulary. Fortunately, the `Lexicon` can be iterated easily from Python:"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":585,"status":"ok","timestamp":1615971875714,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"us2mAzTW7Bny","outputId":"e10d37e2-84a4-448d-9ed9-3d72a5ad5ab7"},"outputs":[{"name":"stdout","output_type":"stream","text":["document (<class 'str'>) -> term0 Nt=3 TF=4 maxTF=2 @{0 0 0} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","first (<class 'str'>) -> term1 Nt=1 TF=1 maxTF=1 @{0 0 7} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","topic (<class 'str'>) -> term2 Nt=1 TF=1 maxTF=1 @{0 1 1} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n","unknown (<class 'str'>) -> term3 Nt=1 TF=1 maxTF=1 @{0 1 5} (<class 'jnius.reflect.org.terrier.structures.LexiconEntry'>)\n"]}],"source":["for kv in index.getLexicon():\n","  print(\"%s (%s) -> %s (%s)\" % (kv.getKey(), type(kv.getKey()), kv.getValue().toString(), type(kv.getValue()) ) )"]},{"cell_type":"markdown","metadata":{"id":"fwbp94gh86pw"},"source":["Here, iterating over the `Lexicon` returns a pair of `String ` term and a [`LexiconEntry`](http://terrier.org/docs/current/javadoc/org/terrier/structures/LexiconEntry.html) object – which itself is an [`EntryStatistics`](http://terrier.org/docs/current/javadoc/org/terrier/structures/EntryStatistics.html) – and contains information including the statistics of that term.\n","\n","\n","So what did we find? Here are some observations:\n"," - we only have 4 unique terms, as stopwords were removed;\n"," - we have one term for `\"document\"`, even though `\"documents\"` occurred in document \"`d1`\". \n"," \n","Both these observations make sense, as indeed Terrier removes standard stopwords and applies Porter's stemmer by default.\n","\n","Further:\n"," - `Nt` is the number of unique documents that each term occurs in – this is useful for calculating IDF.\n"," - `TF` is the total number of occurrences – some weighting models use this instead of Nt.\n"," - The numbers in the `@{}` are a pointer – they tell Terrier where the postings are for that term in the inverted index data structure.\n","\n","Finally, we can also use the square bracket notation to lookup terms in Terrier's lexicon:\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"elapsed":591,"status":"ok","timestamp":1615972070133,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"SZmi9498-Ijw","outputId":"1dccc860-2f99-4e62-b1cc-da4918003b11"},"outputs":[{"data":{"text/plain":["'term0 Nt=3 TF=4 maxTF=2 @{0 0 0}'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["index.getLexicon()[\"document\"].toString()"]},{"cell_type":"markdown","metadata":{"id":"vaKaU59l-kzg"},"source":["Let's now think about the inverted index. Remember that the inverted index tells us in which *documents* each term occurs in. The `LexiconEntry` is the pointer that tell us where to find the postings for that term in the inverted index."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":640,"status":"ok","timestamp":1615972108524,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"XQki_Pds8ut2","outputId":"f7824c65-33d9-499f-f9dc-97d8d7e652c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["ID(0) TF(2) doclen=3\n","ID(1) TF(1) doclen=1\n","ID(2) TF(1) doclen=3\n"]}],"source":["pointer = index.getLexicon()[\"document\"]\n","for posting in index.getInvertedIndex().getPostings(pointer):\n","    print(posting.toString() + \" doclen=%d\" % posting.getDocumentLength())"]},{"cell_type":"markdown","metadata":{"id":"l7EaoIIO_DPx"},"source":["Ok, so we can see that `\"document\"` occurs once in each of the three documents. \n","\n","NB: Terrier counts documents as integers from 0 (called *docids*). It records the mapping back to *docnos* (the string form, i.e. \"`d1`\", \"`d2`\") in a separate data structure called the *metaindex*."]},{"cell_type":"markdown","metadata":{"id":"zOSdVAr-CGRf"},"source":["### Searching an Index\n","\n","Our way into search in PyTerrier is called `BatchRetrieve`. BatchRetrieve is configured by specifying an index and a weighting model (`Tf` in our example). We then search for a single-word query, `\"document\"`."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"elapsed":1097,"status":"ok","timestamp":1615972796605,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"XtK93nwXCF5C","outputId":"f10dccb8-7d91-44ba-8afa-b21b32022999"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score     query\n","0   1      0    d1     0    2.0  document\n","1   1      1    d2     1    1.0  document\n","2   1      2    d3     2    1.0  document"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["br = pt.BatchRetrieve(index, wmodel=\"Tf\")\n","br.search(\"document\")"]},{"cell_type":"markdown","metadata":{"id":"BHqSfTCtDM2T"},"source":["So the `search()` method returns a dataframe with columns:\n"," - `qid`: this is by default \"1\", since it's our first and only query\n"," - `docid`: Terrier' internal integer for each document\n"," - `docno`: the external (string) unique identifier for each document\n"," - `score`: since we use the `Tf` weighting model, this score corresponds the total frequency of the query (terms) in each document\n"," - `rank`: A handy attribute showing the descending order by score\n"," - `query`: the input query\n","\n","As expected, the `Tf` weighting model used here only counts the frequencies of the query terms in each document, i.e.:\n","$$\n","score(d,q) = \\sum_{t \\in q} tf_{t,d}\n","$$\n","\n","Hence, it's clear that document `d1` should be the highest scored document with two occurrences (c.f. `'document'` and `'documents'`).  "]},{"cell_type":"markdown","metadata":{"id":"BJBXquPOD6q7"},"source":["We can also pass a dataframe of one or more queries to the `transform()` method (rather than the `search()` method) of a transformer, with queries numbered \"q1\", \"q2\" etc.. "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1615972799893,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"TPBmPOETBKWk","outputId":"69bf68d3-5e95-403d-f5f8-76bbd7cdaba9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q2</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q2</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>q2</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score           query\n","0  q1      0    d1     0    2.0        document\n","1  q1      1    d2     1    1.0        document\n","2  q1      2    d3     2    1.0        document\n","3  q2      0    d1     0    3.0  first document\n","4  q2      1    d2     1    1.0  first document\n","5  q2      2    d3     2    1.0  first document"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","queries = pd.DataFrame([[\"q1\", \"document\"], [\"q2\", \"first document\"]], columns=[\"qid\", \"query\"])\n","br.transform(queries)"]},{"cell_type":"markdown","metadata":{"id":"tcgDzFLBEWAI"},"source":["In fact, we are usually calling `transform()`, so it's the default method – i.e. \n","`br.transform(queries)` can be more succinctly written as `br(queries)`."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":655,"status":"ok","timestamp":1615972806683,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"YCwxb3HhEOp_","outputId":"b0cfe94b-c1d7-4ac8-811d-befc9771ce32"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q1</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>2.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q1</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q1</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>document</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q2</td>\n","      <td>0</td>\n","      <td>d1</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q2</td>\n","      <td>1</td>\n","      <td>d2</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>q2</td>\n","      <td>2</td>\n","      <td>d3</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>first document</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid  docid docno  rank  score           query\n","0  q1      0    d1     0    2.0        document\n","1  q1      1    d2     1    1.0        document\n","2  q1      2    d3     2    1.0        document\n","3  q2      0    d1     0    3.0  first document\n","4  q2      1    d2     1    1.0  first document\n","5  q2      2    d3     2    1.0  first document"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["br(queries)"]},{"cell_type":"markdown","metadata":{"id":"ldY8VV8wQ60Z"},"source":["### CORD19\n","\n","OK, having 3 documents is quite trivial, so let's move upto a slightly larger corpus of documents. We'll be using the CORD19 datasets for the remainder of this tutorial. PyTerrier has a handy `get_dataset()` API, which allows us to download the corpus and index it."]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120273,"status":"ok","timestamp":1615972928650,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"L2lJsK-vEcQx","outputId":"bcdfe9c5-7950-4974-a97d-ab3764995115"},"outputs":[],"source":["import os\n","\n","cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n","pt_index_path = './terrier_cord19'\n","\n","if not os.path.exists(pt_index_path + \"/data.properties\"):\n","  # create the index, using the IterDictIndexer indexer \n","  indexer = pt.index.IterDictIndexer(pt_index_path)\n","\n","  # we give the dataset get_corpus_iter() directly to the indexer\n","  # while specifying the fields to index and the metadata to record\n","  index_ref = indexer.index(cord19.get_corpus_iter(), \n","                            fields=('abstract',), \n","                            meta=('docno',))\n","\n","else:\n","  # if you already have the index, use it.\n","  index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n","index = pt.IndexFactory.of(index_ref)\n"]},{"cell_type":"markdown","metadata":{"id":"y7GK9uANRt8w"},"source":["#### Task 1\n","- What are the statistics of our index?"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"bNAVqf9uRr2p"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of documents: 192509\n","Number of terms: 151235\n","Number of postings: 11554033\n","Number of fields: 1\n","Number of tokens: 17728468\n","Field names: [abstract]\n","Positions:   false\n","\n"]}],"source":["#YOUR SOLUTION\n","print(index.getCollectionStatistics().toString())"]},{"cell_type":"markdown","metadata":{"id":"tQD9Q8CqSirN"},"source":["Next, CORD19 also has a corresponding set of queries and relevance assessments (aka qrels), thus forming a *test collection*, \n","\n","We can easily access the topics and qrels from the dataset. Indeed these are expressed as dataframes as well (we use Pandas's [`head()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method to show only the first 5 topics):"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"executionInfo":{"elapsed":961,"status":"ok","timestamp":1615972942774,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"8n7oY-YYS_-A","outputId":"6ff6f437-725f-4b92-bfab-787e18386941"},"outputs":[{"name":"stderr","output_type":"stream","text":["[INFO] [starting] https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml\n","[INFO] [finished] https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml: [00:00] [18.7kB] [18.0MB/s]\n","                                                                                 \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>coronavirus origin</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>coronavirus response to weather changes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>coronavirus immunity</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>how do people die from the coronavirus</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>animal models of covid 19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  qid                                    query\n","0   1                       coronavirus origin\n","1   2  coronavirus response to weather changes\n","2   3                     coronavirus immunity\n","3   4   how do people die from the coronavirus\n","4   5                animal models of covid 19"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["cord19.get_topics(variant='title').head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"executionInfo":{"elapsed":1704,"status":"ok","timestamp":1615972945620,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"-rYxqvhJTGNX","outputId":"e4db9772-f10f-4133-bc25-aee1a6f5a0ba"},"outputs":[],"source":["cord19.get_qrels().head(5)"]},{"cell_type":"markdown","metadata":{"id":"2Gop4-jVbIIu"},"source":["### Weighting Models\n","\n","So far, we have been using the simple \"`Tf`\" as our ranking function for document retrieval in BatchRetrieve. However, we can use other models such as `\"TF_IDF\"` by simply changing the `wmodel=\"Tf\"` keyword argument in the constructor of `BatchRetrieve`.\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":945,"status":"ok","timestamp":1615973062514,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"Cg8AGzCibdPG","outputId":"bc353f41-1c33-468c-a834-37a93f1d0ced"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>18717</td>\n","      <td>iavwkdpr</td>\n","      <td>0</td>\n","      <td>11.035982</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>171636</td>\n","      <td>v3blnh02</td>\n","      <td>1</td>\n","      <td>10.329726</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>147193</td>\n","      <td>ei4rb8fr</td>\n","      <td>2</td>\n","      <td>10.317138</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>121217</td>\n","      <td>msdycum2</td>\n","      <td>3</td>\n","      <td>9.653734</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>170863</td>\n","      <td>sj8i9ss2</td>\n","      <td>4</td>\n","      <td>9.500211</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>1</td>\n","      <td>2428</td>\n","      <td>38aabxh1</td>\n","      <td>995</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>1</td>\n","      <td>14752</td>\n","      <td>u709r8ss</td>\n","      <td>996</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>1</td>\n","      <td>20074</td>\n","      <td>wxi1xsbo</td>\n","      <td>997</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>1</td>\n","      <td>117156</td>\n","      <td>ts3obwts</td>\n","      <td>998</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1</td>\n","      <td>149517</td>\n","      <td>6i3x49p8</td>\n","      <td>999</td>\n","      <td>3.790183</td>\n","      <td>chemical reactions</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 6 columns</p>\n","</div>"],"text/plain":["    qid   docid     docno  rank      score               query\n","0     1   18717  iavwkdpr     0  11.035982  chemical reactions\n","1     1  171636  v3blnh02     1  10.329726  chemical reactions\n","2     1  147193  ei4rb8fr     2  10.317138  chemical reactions\n","3     1  121217  msdycum2     3   9.653734  chemical reactions\n","4     1  170863  sj8i9ss2     4   9.500211  chemical reactions\n","..   ..     ...       ...   ...        ...                 ...\n","995   1    2428  38aabxh1   995   3.790183  chemical reactions\n","996   1   14752  u709r8ss   996   3.790183  chemical reactions\n","997   1   20074  wxi1xsbo   997   3.790183  chemical reactions\n","998   1  117156  ts3obwts   998   3.790183  chemical reactions\n","999   1  149517  6i3x49p8   999   3.790183  chemical reactions\n","\n","[1000 rows x 6 columns]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n","tfidf.search(\"chemical reactions\")"]},{"cell_type":"markdown","metadata":{"id":"m6aZGX9sbdmc"},"source":["You will note that, as expected, the scores of documents ranked by `TF_IDF` are no longer integers. You can see the exact formula used by Terrier from [the Github repo](https://github.com/terrier-org/terrier-core/blob/5.x/modules/core/src/main/java/org/terrier/matching/models/TF_IDF.java#L79).\n","\n","Terrier supports many weighting models – the documentation contains [a list of supported models](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html) - some of which we will discover later in the tutorial.\n"]},{"cell_type":"markdown","metadata":{"id":"YQ0j9lFfx-gO"},"source":["### What is Success?\n","\n","So far, we have been creating search engine models, but we haven't decided if any of them ia actually any good. Let's investigate if we are getting a correct (\"relevant\") document at the first rank."]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":794,"status":"ok","timestamp":1615973109097,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"iyShZYpwwNSx","outputId":"91f1ae8b-8f3a-4547-ae37-d9d808c970ce"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>docid</th>\n","      <th>docno</th>\n","      <th>rank</th>\n","      <th>score</th>\n","      <th>query</th>\n","      <th>label</th>\n","      <th>iteration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>175892</td>\n","      <td>zy8qjaai</td>\n","      <td>0</td>\n","      <td>7.080599</td>\n","      <td>coronavirus origin</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>82224</td>\n","      <td>8ccl9aui</td>\n","      <td>1</td>\n","      <td>6.775667</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>135326</td>\n","      <td>ne5r4d4b</td>\n","      <td>2</td>\n","      <td>6.683114</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>122804</td>\n","      <td>75773gwg</td>\n","      <td>3</td>\n","      <td>6.590340</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>122805</td>\n","      <td>kn2z7lho</td>\n","      <td>4</td>\n","      <td>6.590340</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>1</td>\n","      <td>180809</td>\n","      <td>0y0hau9l</td>\n","      <td>995</td>\n","      <td>4.214228</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>1</td>\n","      <td>148967</td>\n","      <td>f8vbflx6</td>\n","      <td>996</td>\n","      <td>4.212887</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>1</td>\n","      <td>183189</td>\n","      <td>uadfehr6</td>\n","      <td>997</td>\n","      <td>4.210201</td>\n","      <td>coronavirus origin</td>\n","      <td>2.0</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>1</td>\n","      <td>67321</td>\n","      <td>n5hnx2c3</td>\n","      <td>998</td>\n","      <td>4.202319</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1</td>\n","      <td>98706</td>\n","      <td>ad6ztoba</td>\n","      <td>999</td>\n","      <td>4.202319</td>\n","      <td>coronavirus origin</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 8 columns</p>\n","</div>"],"text/plain":["    qid   docid     docno  rank     score               query  label iteration\n","0     1  175892  zy8qjaai     0  7.080599  coronavirus origin    1.0         1\n","1     1   82224  8ccl9aui     1  6.775667  coronavirus origin    2.0         1\n","2     1  135326  ne5r4d4b     2  6.683114  coronavirus origin    0.0       1.5\n","3     1  122804  75773gwg     3  6.590340  coronavirus origin    2.0         5\n","4     1  122805  kn2z7lho     4  6.590340  coronavirus origin    2.0         3\n","..   ..     ...       ...   ...       ...                 ...    ...       ...\n","995   1  180809  0y0hau9l   995  4.214228  coronavirus origin    0.0         0\n","996   1  148967  f8vbflx6   996  4.212887  coronavirus origin    0.0         0\n","997   1  183189  uadfehr6   997  4.210201  coronavirus origin    2.0       1.5\n","998   1   67321  n5hnx2c3   998  4.202319  coronavirus origin    0.0         0\n","999   1   98706  ad6ztoba   999  4.202319  coronavirus origin    0.0         0\n","\n","[1000 rows x 8 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["qrels = cord19.get_qrels()\n","def get_res_with_labels(ranker, df):\n","  # get the results for the query or queries\n","  results = ranker( df )\n","  # left outer join with the qrels\n","  with_labels = results.merge(qrels, on=[\"qid\", \"docno\"], how=\"left\").fillna(0)\n","  return with_labels\n","\n","# lets get the Tf results for the first query\n","get_res_with_labels(tfidf, cord19.get_topics(variant='title').head(1))"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"elapsed":3826,"status":"ok","timestamp":1615973119937,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"},"user_tz":-60},"id":"OFUmiFSobUDg","outputId":"db01e114-e6e7-4ff4-9447-ecf5e3d8ea54"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>map</th>\n","      <th>ndcg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BR(TF_IDF)</td>\n","      <td>0.180002</td>\n","      <td>0.370767</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         name       map      ndcg\n","0  BR(TF_IDF)  0.180002  0.370767"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["pt.Experiment(\n","    [tfidf],\n","    cord19.get_topics(variant='title'),\n","    cord19.get_qrels(),\n","    eval_metrics=[\"map\", \"ndcg\"])"]},{"cell_type":"markdown","metadata":{"id":"Mt0iPhRw2J-S"},"source":["## That's all folks\n","\n","The following parts of the PyTerrier documentation may be useful references for this notebook:\n"," * [PyTerrier datasets](https://pyterrier.readthedocs.io/en/latest/datasets.html)\n"," * [Using Terrier for retrieval](https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html)\n"," * [Transformers in PyTerrier](https://pyterrier.readthedocs.io/en/latest/transformer.html)\n"," * [Transformer Operators](https://pyterrier.readthedocs.io/en/latest/operators.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRjyEZ5_aTvM"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ECIR 2021 Tutorial Notebook - Part 1.ipynb","provenance":[{"file_id":"1kWCNf3QlQ4bX5YCM9OJBaaLikoTFCd5A","timestamp":1615914442515},{"file_id":"17Pihqt_C8DFzqlomTUks-5stNzNFjrAn","timestamp":1611078807322},{"file_id":"121AtOADdFd2VVAX5hcJX0WNBNt2_QHDu","timestamp":1609952873856},{"file_id":"1o4RTKOutf_FlMyPdEPkRyutnbY26JXMf","timestamp":1571324862553}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
